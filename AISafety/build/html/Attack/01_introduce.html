

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>1. 攻击算法详细介绍 &mdash; AISafety 1.0 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="2. 扩展攻击算法" href="02_extend.html" />
    <link rel="prev" title="攻击算法介绍" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> AISafety
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Start/index.html">开始使用</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Dataset/index.html">数据集介绍</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">攻击算法介绍</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#id2">攻击方法</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="index.html#id3">攻击方法（黑白盒</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="index.html#id6">攻击方法（目标/非目标</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="index.html#id7">目标攻击</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html#id8">非目标攻击</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Evaluation/index.html">评测算法介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Defense/index.html">防御算法介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Models/index.html">平台模型介绍</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AISafety</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">攻击算法介绍</a> &raquo;</li>
        
      <li><span class="section-number">1. </span>攻击算法详细介绍</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Attack/01_introduce.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1><span class="section-number">1. </span>攻击算法详细介绍<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>平台已集成的攻击算法及简要说明如下所示(使用攻击算法缩写字典序排序)</p>
<div class="section" id="ba">
<h2><span class="section-number">1.1. </span>BA算法<a class="headerlink" href="#ba" title="永久链接至标题">¶</a></h2>
<div class="section" id="id2">
<h3>算法介绍<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h3>
<p>BA的全称是 Boundary
Attack。该算法使用目标类中的一个样本初始化为非目标攻击，并用一个混合了均匀噪声的样本初始化为目标攻击。算法的每次迭代有三个部分。首先，通过二进制搜索将上次迭代的迭代结果推向边界。</p>
<p><img alt="image1" src="../_images/BA.png" /></p>
<p>接着，通过如下方程估计梯度方向。</p>
<div class="math notranslate nohighlight">
\[\widetilde{\triangledown S} (x^t, \delta):=\frac{1}{B} \sum_{b=1}^{B} \phi_x(x^t+\delta_{u_b})u_b\]</div>
<p>最后通过几何级数选择合适的步长，直到扰动成功。并通过二元搜索将扰动样本推回边界。</p>
</div>
<div class="section" id="id3">
<h3>参数说明<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 36%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>扰动的步长系数</p></td>
</tr>
<tr class="row-odd"><td><p>delta</p></td>
<td><p>重新缩放的扰动的尺寸</p></td>
</tr>
<tr class="row-even"><td><p>lower_bound</p></td>
<td><p>归一化数据上边界</p></td>
</tr>
<tr class="row-odd"><td><p>upper_bound</p></td>
<td><p>归一化数据下边界</p></td>
</tr>
<tr class="row-even"><td><p>max_iter</p></td>
<td><p>扰动样本更新的最大内层迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>binary_search_steps</p></td>
<td><p>搜索ε的迭代次数</p></td>
</tr>
<tr class="row-even"><td><p>batch_size</p></td>
<td><p>单次批处理大小</p></td>
</tr>
<tr class="row-odd"><td><p>step_adapt</p></td>
<td><p>用来更新delta的更新系数</p></td>
</tr>
<tr class="row-even"><td><p>sample_size</p></td>
<td><p>过程中生成的潜在扰动样本的采样数目</p></td>
</tr>
<tr class="row-odd"><td><p>init_size</p></td>
<td><p>初始化的随机样本数目</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="bim">
<h2><span class="section-number">1.2. </span>BIM算法<a class="headerlink" href="#bim" title="永久链接至标题">¶</a></h2>
<div class="section" id="id4">
<span id="id5"></span><h3>算法介绍<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>BIM全称为Basic Iterative Method。FGSM这种one-step
方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到
Basic Iterative
Methods（BIM）。BIM是FGSM的拓展，进行了多次小步的迭代，并且在每一步之后都修剪得到的结果的像素值，来确保得到的结果在原始图像的
ϵ 邻域内，BIM迭代生成对抗样本的公式如下：</p>
<div class="math notranslate nohighlight">
\[X_0^{adv}=X,\; \; X_{N+1}^{adv}=Clip_{X,\epsilon}\{ X_n^{adv} + \alpha sign(\triangledown _X J(X_N^{adv}, y_{true})) \}\]</div>
</div>
<div class="section" id="id6">
<span id="id7"></span><h3>参数说明<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>eps</p></td>
<td><p>原始样本的灰度偏移比例</p></td>
</tr>
<tr class="row-odd"><td><p>eps_iter</p></td>
<td><p>梯度步长的改变比例</p></td>
</tr>
<tr class="row-even"><td><p>num_steps</p></td>
<td><p>多次迭代的次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="blb">
<h2><span class="section-number">1.3. </span>BLB算法<a class="headerlink" href="#blb" title="永久链接至标题">¶</a></h2>
<div class="section" id="id8">
<span id="id9"></span><h3>算法介绍<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<p>BLB的全称是 Box-constrained L-BFGS
attack。该攻击方法通过对图像添加小量的人类察觉不到的扰动误导神经网络做出误分类：</p>
<div class="math notranslate nohighlight">
\[min_{\rho}|| \rho ||_2 \; s.t. C(I_c + \rho) = l;\; I_c + \rho \in [0,1]^m\]</div>
<p>其中Ic∈R<sup>m表示一张干净的图片，ρ∈R</sup>m是一个小的扰动，I是图像的label，C(…)是深度神经网络分类器。l和原本图像的label不一样。</p>
<p>但由于问题的复杂度太高，转而求解简化后的问题，即寻找最小的损失函数添加项，使得神经网络做出误分类，这就将问题转化成了凸优化过程。</p>
<div class="math notranslate nohighlight">
\[min_{\rho} \; c|\rho| + L(I_c + \rho, l)\; \; s.t. I_c + \rho \in [0,1]^m\]</div>
<p>L(.,.)计算分类器的loss。通过凸优化的手段得到最终的噪音。</p>
</div>
<div class="section" id="id10">
<span id="id11"></span><h3>参数说明<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 28%" />
<col style="width: 72%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>init_const</p></td>
<td><p>二分搜索的参数的初始值，用于初始扰动图像的数据产生</p></td>
</tr>
<tr class="row-odd"><td><p>binary_search_steps</p></td>
<td><p>二分搜索的一次循环步长</p></td>
</tr>
<tr class="row-even"><td><p>max_iter</p></td>
<td><p>使用LBFGS，torch的优化器优化扰动值的最大迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="corrupt">
<h2><span class="section-number">1.4. </span>Corrupt算法<a class="headerlink" href="#corrupt" title="永久链接至标题">¶</a></h2>
<div class="section" id="id12">
<span id="id13"></span><h3>算法介绍<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h3>
<p>Corrupt算法将自然噪声加入到原始样本后所产生的攻击样本，用于评测模型的鲁棒性。其中，自然噪音（corruption）是指经常出现在自然场景中且对模型的任务产生一定不良影响的噪音，如：高斯噪音、强烈的对比度变化、雪、雾等。包含：</p>
<blockquote>
<div><p>gaussian_noise 高斯噪声</p>
<p>shot_noise 散粒噪声（泊松噪声）</p>
<p>impulse_noise 脉冲噪声</p>
<p>speckle_noise 斑点噪声</p>
<p>gaussian_blur 高斯模糊</p>
<p>glass_blur 毛玻璃</p>
<p>defocus_blur 散焦模糊</p>
<p>motion_blur 运动模糊</p>
<p>zoom_blur 缩放模糊</p>
<p>Fog 烟雾</p>
<p>Frost 水雾</p>
<p>Snow 雪</p>
<p>Spatter 喷溅</p>
<p>Contrast 对比度噪声</p>
<p>Brightness 过曝光</p>
<p>Saturate 饱和</p>
<p>jpeg_compression jpeg压缩产生的损失</p>
<p>Pixelate 像素化</p>
<p>elastic_transform 弹性变换</p>
</div></blockquote>
</div>
<div class="section" id="id14">
<span id="id15"></span><h3>参数说明<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 87%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>severtiy</p></td>
<td><p>选择待选参数，1是第一个，2就是第二个，暂时不开放给用户</p></td>
</tr>
<tr class="row-odd"><td><p>gama</p></td>
<td><p>决定迭代次数的和图像尺度大小相关的一个比例系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="cw2">
<h2><span class="section-number">1.5. </span>CW2算法<a class="headerlink" href="#cw2" title="永久链接至标题">¶</a></h2>
<div class="section" id="id16">
<span id="id17"></span><h3>算法介绍<a class="headerlink" href="#id16" title="永久链接至标题">¶</a></h3>
<p>CW2算法的全称是 Carlini &amp; Wagner Attack。Carlini 和Wagner
为了攻击防御性蒸馏(Defensive
distillation)网络提出了三种对抗攻击方法，通过限制
l0,l1,l∞范数使得扰动无法被察觉。实验证明蒸馏网络完全无法防御这三种攻击。该算法生成的对抗扰动可以从unsecured网络迁移到secured网络上，从而实现黑箱攻击。实验表明，C&amp;W攻击方法能有效攻击现有的大多数防御方法。</p>
<p>目标函数表示为：</p>
<div class="math notranslate nohighlight">
\[min_{\delta} D(x,x+\delta)+c \cdot f(x+\delta)\, subject \; to \; x + \delta \in [0,1]\]</div>
<p>式中，δ 是对抗扰动；D(∙,∙)表示L0、L2或L∞距离度量；f(x
+δ)是自定义的对抗损失，当且仅当DNN的预测为攻击目标时才满足f(x
+δ)≤0。为了确保x + δ产生能有效的</p>
<p>图像（即x +δ ∈ [0, 1]），引入了一个新变量来代替δ：</p>
<div class="math notranslate nohighlight">
\[\delta = \frac{1}{2}(tanh(K) + 1) - x\]</div>
<p>这样，x + δ =1/2(tanh(k) + 1)在优化过程中始终位于[0,
1]中。除了在MNIST、CIFAR10和ImageNet的正常训练DNN模型上获得100%的攻击成功率外，C&amp;W攻击还可以破坏防御性蒸馏模型，而这些模型可以使L-BFGS和Deepfool无法找到对抗性样本。</p>
</div>
<div class="section" id="id18">
<span id="id19"></span><h3>参数说明<a class="headerlink" href="#id18" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 65%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>dataset</p></td>
<td><p>使用的数据集的名称</p></td>
</tr>
<tr class="row-odd"><td><p>class_type_num</p></td>
<td><p>分类网络的类别</p></td>
</tr>
<tr class="row-even"><td><p>kappa</p></td>
<td><p>标签的序号的整体偏移量</p></td>
</tr>
<tr class="row-odd"><td><p>learning_rate</p></td>
<td><p>迭代过程中优化器的学习率</p></td>
</tr>
<tr class="row-even"><td><p>init_const</p></td>
<td><p>初始的迭代求解参数的值</p></td>
</tr>
<tr class="row-odd"><td><p>lower_bound</p></td>
<td><p>产生中间扰动样本的值的下边界</p></td>
</tr>
<tr class="row-even"><td><p>upper_bound</p></td>
<td><p>产生中间扰动样本的值的上边界</p></td>
</tr>
<tr class="row-odd"><td><p>max_iter</p></td>
<td><p>为了生成合适的扰动样本时候的迭代次数</p></td>
</tr>
<tr class="row-even"><td><p>binary_search_steps</p></td>
<td><p>为了求解合适的参数的搜索迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="deepfool">
<h2><span class="section-number">1.6. </span>Deepfool算法<a class="headerlink" href="#deepfool" title="永久链接至标题">¶</a></h2>
<div class="section" id="id20">
<span id="id21"></span><h3>算法介绍<a class="headerlink" href="#id20" title="永久链接至标题">¶</a></h3>
<p>对于多分类问题，通常采取的方案为一对多。在这里，针对多个输出类别，通过下式进行分类选择：</p>
<div class="math notranslate nohighlight">
\[\hat{k}(x)=\underset{k}{arg\, max}f_k(x)\]</div>
<p>对于线性多分类器，我们有：</p>
<div class="math notranslate nohighlight">
\[f(x)=W^Tx+b\]</div>
<p>最小扰动可以由下式计算：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ \underset{r}{arg\, min}\left |\left |r \right | \right |_2
\\ s.t. \; \exists k: w_k^T(x_0 + r) + b_k \geq w_{\hat{k}(x_0)}^T(x_0+r)+b_{\hat{k}(x_0)}\end{split}\]</div>
<p>为了解这个问题，我们先来看一个四分类问题的例子：</p>
<p><img alt="image2" src="../_images/图片18.png" /></p>
<p>注意，这里只有三条线，分别对应前三类的参数超平面与第四类相减得到的参数超平面。同样利用点到直线的距离公式，若求得到这三条线的最短距离便可得到使样本分类发生变化的最小扰动长度。最短距离可以用下式计算：</p>
<div class="math notranslate nohighlight">
\[\hat{l}(x_0)=\underset{k\neq \hat{k}(x_0)}{arg \, min} \frac{\left| f_k(x_0) - f_{\hat{k}(x_0)}(x_0) \right |}{\left | \left | w_k - w_{\hat{k}(x_0)} \right | \right |_2}\]</div>
<p>因此最小扰动向量为：</p>
<div class="math notranslate nohighlight">
\[r_*(x_0)=\frac{\left| f_{\hat{l}(x_0)}(x_0) - f_{\hat{k}(x_0)}(x_0) \right |}{\left | \left | w_{\hat{l}(x_0)} - w_{\hat{k}(x_0)} \right | \right |_2^2}(w_{\hat{l}(x_0)} - w_{\hat{k}(x_0)})\]</div>
<p>对于一般的多分类问题，同样利用近似线性的方法迭代得到，算法如下：</p>
<p><img alt="image3" src="../_images/图片19.png" /></p>
<p>注意，这个算法并不能保证收敛到最小扰动解。算法中2范数可以扩展到p范数。</p>
</div>
<div class="section" id="id22">
<span id="id23"></span><h3>参数说明<a class="headerlink" href="#id22" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 80%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>overshoot</p></td>
<td><p>防止算法收敛到分类面上</p></td>
</tr>
<tr class="row-odd"><td><p>max_iter</p></td>
<td><p>为了生成合适的扰动样本时候的迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="ead">
<h2><span class="section-number">1.7. </span>EAD算法<a class="headerlink" href="#ead" title="永久链接至标题">¶</a></h2>
<div class="section" id="id24">
<span id="id25"></span><h3>算法介绍<a class="headerlink" href="#id24" title="永久链接至标题">¶</a></h3>
<p>EAD的全称是 Elastic-net Attacks to DNNs。EAD将使用对抗样本攻击 DNN
的过程转化为了使用弹性网络正则化（elastic-net
regularized）的优化问题。在这种表示下，当前最佳的 L2
范数攻击算法成为了本文方法的一个特例（在不考虑 L1 范数的情况下）。在
MNIST、CIFAR10 和 ImageNet 上的实验结果表明 EAD 算法可以生成具有很小 L1
失真的对抗样本，并且能在不同攻击场景中实现与当前最佳方法匹敌的攻击成功率。更重要的是，EAD
算法生成的对抗样本有着显著增强的攻击可迁移性，这为如何在对抗机器学习中使用
L1 范数失真以及增强 DNN
的安全性提供了全新的见解。下图是EAD算法的伪代码：</p>
<p><img alt="image4" src="../_images/图片20.png" /></p>
</div>
<div class="section" id="id26">
<span id="id27"></span><h3>参数说明<a class="headerlink" href="#id26" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 39%" />
<col style="width: 61%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>lr</p></td>
<td><p>学习率</p></td>
</tr>
<tr class="row-odd"><td><p>kapa</p></td>
<td><p>标签的偏移值</p></td>
</tr>
<tr class="row-even"><td><p>binary_search_steps</p></td>
<td><p>用来搜索合适的参数的迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>init_const</p></td>
<td><p>初始化的调节系数</p></td>
</tr>
<tr class="row-even"><td><p>lower_bound</p></td>
<td><p>产生中间扰动样本的值的下边界</p></td>
</tr>
<tr class="row-odd"><td><p>upper_bound</p></td>
<td><p>产生中间扰动样本的值的上边界</p></td>
</tr>
<tr class="row-even"><td><p>max_iter</p></td>
<td><p>扰动样本更新的最大内层迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>class_type_number</p></td>
<td><p>分类类别的数目</p></td>
</tr>
<tr class="row-even"><td><p>beta</p></td>
<td><p>扰动样本的初始灰度波动值</p></td>
</tr>
<tr class="row-odd"><td><p>EN</p></td>
<td><p>决策规则的选择</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="fgsm">
<h2><span class="section-number">1.8. </span>FGSM算法<a class="headerlink" href="#fgsm" title="永久链接至标题">¶</a></h2>
<div class="section" id="id28">
<span id="id29"></span><h3>算法介绍<a class="headerlink" href="#id28" title="永久链接至标题">¶</a></h3>
<p>FGSM的全称是Fast Gradient Sign
Method(快速梯度下降法），在白盒环境下，通过求出模型对输入的导数，然后用符号函数得到其具体的梯度方向，接着乘以一个步长，得到的“扰动”加在原来的输入
上就得到了在FGSM攻击下的样本。</p>
<p>FGSM的攻击表达如下：</p>
<div class="math notranslate nohighlight">
\[x^{'}=x+\varepsilon \cdot sign(\triangledown_x J(x, y))\]</div>
<p>攻击成功就是模型分类错误，就模型而言，就是加了扰动的样本使得模型的loss增大。而所有基于梯度的攻击方法都是基于让loss增大这一点来做的。可以仔细回忆一下，在神经网络的反向传播当中，我们在训练过程时就是沿着梯度方向来更新更新w，b的值。这样做可以使得网络往loss减小的方向收敛。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ W_{ij}^{(l)}=W_{ij}^{(l)}-\alpha \frac{\partial}{\partial  W_{ij}^{(l)}}J(W,b)
\\ b_{i}^{(l)}=b_{i}^{(l)}-\alpha \frac{\partial}{\partial  b_{i}^{(l)}}J(W,b)\end{split}\]</div>
<p>那么现在我们既然是要使得loss增大，而模型的网络系数又固定不变，唯一可以改变的就是输入，因此我们就利用loss对输入求导从而“更新”这个输入。</p>
</div>
<div class="section" id="id30">
<span id="id31"></span><h3>参数说明<a class="headerlink" href="#id30" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>沿着梯度的步长系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="illc">
<h2><span class="section-number">1.9. </span>ILLC<a class="headerlink" href="#illc" title="永久链接至标题">¶</a></h2>
<div class="section" id="id32">
<span id="id33"></span><h3>算法介绍<a class="headerlink" href="#id32" title="永久链接至标题">¶</a></h3>
<p>ILLC的全称是Iterative Least Likely Class Attack，先介绍一下
one-Step的方法。 one-step target class methods:</p>
<div class="math notranslate nohighlight">
\[X^{adv}=x-\epsilon sign(\triangledown_{X}J(X,y_{target}))\]</div>
<p>其中</p>
<div class="math notranslate nohighlight">
\[y_{target}=\underset{y}{argmin}p(y|X)\]</div>
<p>即偏离最远的错误类。这里产生的攻击样本是其中一个候选样本，当只计算完成一个梯度的时候，一般是通过线性扰动的损失函数，而迭代方式可以应用更多的梯度更新，它们通常不依赖于模型的任何近似值，并且在进行更多迭代时通常会产生更多有效果和攻击性的对抗样本（图像），也就是说ILLR迭代方式是one-Step的“升级版”。</p>
<div class="math notranslate nohighlight">
\[X_0^{adv} = X,X_{N+1}^{adv}=Clip_{X,\epsilon}(X_N^{adv}-\alpha sign(\triangledown_{X}J(X_N^{adv}, y_{target})))\]</div>
<p>损失函数是：</p>
<div class="math notranslate nohighlight">
\[Loss=\frac{1}{(m-k)+\lambda k}\left (\sum_{i \in CLEAN}L(X_i|y_i)+\lambda \sum_{i \in ADV}L(X_i^{adv}|y_i)  \right )\]</div>
<p>其中L(X|y)是单个样本X对于真实标记y的损失函数，m是小批量上的训练样本总数，k是小批量内对抗样本的数目而λ是参数来控制对抗样本对于损失函数的权重。</p>
<p>算法过程：</p>
<p><img alt="image5" src="../_images/图片21.png" /></p>
</div>
<div class="section" id="id34">
<span id="id35"></span><h3>参数说明<a class="headerlink" href="#id34" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 38%" />
<col style="width: 63%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>样本归一化的偏移比例</p></td>
</tr>
<tr class="row-odd"><td><p>epsilon_iter</p></td>
<td><p>沿着梯度的步长系数</p></td>
</tr>
<tr class="row-even"><td><p>num_steps</p></td>
<td><p>迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="jsm">
<h2><span class="section-number">1.10. </span>JSM<a class="headerlink" href="#jsm" title="永久链接至标题">¶</a></h2>
<div class="section" id="id36">
<span id="id37"></span><h3>算法介绍<a class="headerlink" href="#id36" title="永久链接至标题">¶</a></h3>
<p>JSM算法的全称是Jacobian-based Saliency Map Attack</p>
<p>目标是只修改图像中的几个像素，而不是扰乱整个图像来欺骗分类器,该算法一次修改一个干净图像的像素，并监测变化对结果分类的影响。通过使用网络层的输出的梯度来计算一个显著性图来执行监控。</p>
<p>JSMA算法主要包括三个过程：计算前向导数，计算对抗性显著图，添加扰动，以下给出具体解释。</p>
<p>所谓前向导数，其实是计算神经网络最后一层的每一个输出对输入的每个特征的偏导。以MNIST分类任务为例，输入的图片的特征数（即像素点）为784，神经网络的最后一层一般为10个输出（分别对应0-9分类权重），那对于每一个输出我们都要分别计算对784个输入特征的偏导，所以计算结束得到的前向导数的矩阵为（10，784）。前向导数标识了每个输入特征对于每个输出分类的影响程度，其计算过程也是采用链式法则。这里需要说明一下，前面讨论过的FGSM和DeepFool不同在计算梯度时，是通过对损失函数求导得到的，而JSMA中前向导数是通过对神经网络最后一层输出求导得到的。前向导数∇F(X)具体计算过程如下所示，j表示对应的输出分类，i表示对应的输入特征。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ \triangledown F(X)=\frac{\partial F(X)}{\partial X}=\left [ \frac{\partial F_j(X)}{\partial x_i} \right ]_{i \in 1...M,j \in 1...N}
\\ \frac{\partial F_j(X)}{\partial x_i}=\left( W_{n+1,j} \cdot \frac{\partial H_n}{\partial x_i} \right ) \times \frac{\partial f_{n+1,j}}{\partial x_i}\left( W_{n+1,j} \cdot H_n + b_{n + 1, j} \right )\end{split}\]</div>
<p>通过得到的前向导数，我们可以计算其对抗性显著图，即对分类器特定输出影响程度最大的输入。首先，根据扰动方式的不同（正向扰动和反向扰动），作者提出了两种计算对抗性显著图的方式，即：</p>
<div class="math notranslate nohighlight">
\[\begin{split}S(X,t)[i]= \left\{\begin{matrix} 0 &amp; if \: \frac{\partial F_t(X)}{\partial X_i} &lt; 0 \: or \: \sum_{j \neq t} \frac{\partial F_j(X)}{\partial X_i} &gt; 0
\\ \left( \frac {\partial F_t(X)}{\partial X_i} \left | \sum_{j \neq t} \frac{\partial F_j(X)}{\partial X_i} \right | \right ) &amp; otherwise
\end{matrix}\right.\end{split}\]</div>
<p>但是在文章中第四部分的应用中作者发现，找到单个满足要求的特征很困难，所以作者提出了另一种解决方案，通过对抗性显著图寻找对分类器特定输出影响程度最大的输入特征对，即每次计算得到两个特征。</p>
<div class="math notranslate nohighlight">
\[argmax_{p1,p2}\left( \sum_{i=p1,p2} \frac{\partial F_t(X)}{\partial X_i} \right) \times \left| \sum_{i=p1,p2} \sum_{j \neq t} \frac{\partial F_j(X)}{\partial X_i} \right |\]</div>
<p>算法具体过程：</p>
<p><img alt="image6" src="../_images/图片22.png" /></p>
</div>
<div class="section" id="id38">
<span id="id39"></span><h3>参数说明<a class="headerlink" href="#id38" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>theta</p></td>
<td><p>样本一维度化之
后（拉平）对图像的灰度的增减。小于0是降低，大于0是增加。</p></td>
</tr>
<tr class="row-odd"><td><p>gama</p></td>
<td><p>决定迭代次数的和图像尺度大小相关的一个比例系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="llc">
<h2><span class="section-number">1.11. </span>LLC算法<a class="headerlink" href="#llc" title="永久链接至标题">¶</a></h2>
<div class="section" id="id40">
<span id="id41"></span><h3>算法介绍<a class="headerlink" href="#id40" title="永久链接至标题">¶</a></h3>
<p>LLC算法的全称为Least-Likely-Class Iterative Methods。</p>
<p>one-step
方法通过一大步运算增大分类器的损失函数而进行图像扰动，因而可以直接将其扩展为通过多个小步增大损失函数的变体，从而我们得到
Basic Iterative
Methods（BIM）。而该方法的变体和前述方法类似，通过用识别概率最小的类别（目标类别）代替对抗扰动中的类别变量，而得到
Least-Likely-Class Iterative Methods。</p>
<div class="math notranslate nohighlight">
\[y_{LL}=\underset{y}{arg\, min} \{ p(y|X) \}\]</div>
<p>这里X是原始的图像，攻击样本：</p>
<div class="math notranslate nohighlight">
\[X_0^{adv}=X, \; X_{N+1}^{adv}=Clip_{X,\epsilon}\{ X_N^{adv} - \alpha sign(\triangledown _X J(X_N^{adv}, y_{LL})) \}\]</div>
</div>
<div class="section" id="id42">
<span id="id43"></span><h3>参数说明<a class="headerlink" href="#id42" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>eps</p></td>
<td><p>沿着梯度的步长系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="nes">
<h2><span class="section-number">1.12. </span>NES算法<a class="headerlink" href="#nes" title="永久链接至标题">¶</a></h2>
<div class="section" id="id44">
<span id="id45"></span><h3>算法介绍<a class="headerlink" href="#id44" title="永久链接至标题">¶</a></h3>
<p>NES算法的全称为Nature Evolutionary Strategies</p>
</div>
<div class="section" id="id46">
<span id="id47"></span><h3>参数说明<a class="headerlink" href="#id46" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 28%" />
<col style="width: 72%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>learning_rate</p></td>
<td><p>学习率</p></td>
</tr>
<tr class="row-odd"><td><p>lower_bound</p></td>
<td><p>产生中间扰动样本的值的下边界</p></td>
</tr>
<tr class="row-even"><td><p>upper_bound</p></td>
<td><p>产生中间扰动样本的值的上边界</p></td>
</tr>
<tr class="row-odd"><td><p>max_iter</p></td>
<td><p>扰动样本更新的最大内层迭代次数</p></td>
</tr>
<tr class="row-even"><td><p>binary_search_steps</p></td>
<td><p>用来搜索合适的参数的迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>batch_size</p></td>
<td><p>单次批处理数目</p></td>
</tr>
<tr class="row-even"><td><p>kappa</p></td>
<td><p>标签的序号的整体偏移量</p></td>
</tr>
<tr class="row-odd"><td><p>sigma</p></td>
<td><p>随机样本分布的标准差</p></td>
</tr>
<tr class="row-even"><td><p>class_type_number</p></td>
<td><p>分类类别的数目</p></td>
</tr>
<tr class="row-odd"><td><p>confidence</p></td>
<td><p>帮助判断攻击类别和预测类别是否相同或者有固定偏差</p></td>
</tr>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>扰动的步长系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="om">
<h2><span class="section-number">1.13. </span>OM算法<a class="headerlink" href="#om" title="永久链接至标题">¶</a></h2>
<div class="section" id="id48">
<span id="id49"></span><h3>算法介绍<a class="headerlink" href="#id48" title="永久链接至标题">¶</a></h3>
<p>OM算法的全称为OPTMARGIN
attack，它可以生成低失真的对抗示例，对小扰动具有鲁棒性，例如在区域分类中使用的小扰动。</p>
<p>在OPTMARGIN攻击中，创建了区域分类器的替代模型，该模型干扰输入点比较少。</p>
<p>这里f是用来区域分类的点分类器，vi是作用在输入样本x上的扰动。该攻击使用现有的优化攻击技术来生成示例，愚弄整个过程的同时最大程度地减少其失真。</p>
<div class="math notranslate nohighlight">
\[l_i(x^{'})=l(x^{'}+v_i)=max(-k, Z(x^{'} + v_i)_y - max\{ Z(x^{'} + v_i)_j : j \neq y \})\]</div>
<p>这里k=0，这意味着，只要能产生错分类，就可以接受。通过这些损失方程，作者扩展了Carlini＆Wagner的L2攻击，有：</p>
<div class="math notranslate nohighlight">
\[minimize || x^{'} - x ||_2^2 + c \cdot (l_1(x^{'})+...+l_n(x^{'}))\]</div>
<p>作者选用了20种分类器，在攻击过程中，v1,v2,…,v19，都是量级归一化到ε上的随机正交向量，v20=0,此选择是为了使随机扰动位于vi中，为了稳定优化器，在攻击过程中，需要固定vi，这个办法在C&amp;W算法中仍然使用过，详细的描述见：<a class="reference external" href="https://openreview.net/pdf?id=BkpiPMbA">https://openreview.net/pdf?id=BkpiPMbA</a>-</p>
</div>
<div class="section" id="id50">
<span id="id51"></span><h3>参数说明<a class="headerlink" href="#id50" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 69%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>lr</p></td>
<td><p>学习率</p></td>
</tr>
<tr class="row-odd"><td><p>kapa</p></td>
<td><p>标签的偏移值</p></td>
</tr>
<tr class="row-even"><td><p>binary_search_steps</p></td>
<td><p>用来搜索合适的参数的迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>init_const</p></td>
<td><p>初始化的调节系数</p></td>
</tr>
<tr class="row-even"><td><p>lower_bound</p></td>
<td><p>产生中间扰动样本的值的下边界</p></td>
</tr>
<tr class="row-odd"><td><p>upper_bound</p></td>
<td><p>产生中间扰动样本的值的上边界</p></td>
</tr>
<tr class="row-even"><td><p>max_iter</p></td>
<td><p>扰动样本更新的最大内层迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>class_type_number</p></td>
<td><p>分类类别的数目</p></td>
</tr>
<tr class="row-even"><td><p>noise_count</p></td>
<td><p>中间扰动样本的数目，初始都是随机的正交向量</p></td>
</tr>
<tr class="row-odd"><td><p>magnitude</p></td>
<td><p>扰动样本的归一化的正交向量的幅值</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="pgd">
<h2><span class="section-number">1.14. </span>PGD算法<a class="headerlink" href="#pgd" title="永久链接至标题">¶</a></h2>
<div class="section" id="id52">
<span id="id53"></span><h3>算法介绍<a class="headerlink" href="#id52" title="永久链接至标题">¶</a></h3>
<p>PGD全称是Projected Gradient
descent。目的是为解决FGSM和FGM中的线性假设问题，使用PGD方法来求解内部的最大值问题。
PGD是一种迭代攻击，相比于普通的FGSM和FGM
仅做一次迭代，PGD是做多次迭代，每次走一小步，每次迭代都会将扰动投射到规定范围内。</p>
<div class="math notranslate nohighlight">
\[g_t=\triangledown X_t(L(f_\theta (X_t), y))\]</div>
<p>gt 表示t时刻的损失关于t时刻输入的梯度。</p>
<div class="math notranslate nohighlight">
\[X_{t+1} = \prod _{X+S}(X_t+\varepsilon (\frac{g_t}{|| g_t ||}))\]</div>
<p>t+1时刻输入根据t时刻的输入及t时刻的梯度求出。∏_(X+S)的意思是，如果扰动超过一定的范围，就要映射回规定的范围S内。</p>
<p>由于每次只走很小的一步，所以局部线性假设基本成立。经过多步之后就可以达到最优解，也就是达到最强的攻击效果。同时使用PGD算法得到的攻击样本，是一阶对抗样本中最强的。这里所说的一阶对抗样本是指依据一阶梯度的对抗样本。如果模型对PGD产生的样本鲁棒，那基本上就对所有的一阶对抗样本都鲁棒。实验也证明，利用PGD算法进行对抗训练的模型确实具有很好的鲁棒性。</p>
<p>PGD虽然简单，也很有效，但是存在一个问题是计算效率不高。不采用提对抗训练的方法m次迭代只会有m次梯度的计算，但是对于PGD而言，每做一次梯度下降（获取模型参数的梯度，训练模型），都要对应有K步的梯度提升（获取输出的梯度，寻找扰动）。所以相比不采用对抗训练的方法，PGD需要做m(K+1)次梯度计算。</p>
</div>
<div class="section" id="id54">
<span id="id55"></span><h3>参数说明<a class="headerlink" href="#id54" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 29%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>eps</p></td>
<td><p>原始样本的灰度偏移比例</p></td>
</tr>
<tr class="row-odd"><td><p>eps_iter</p></td>
<td><p>梯度步长的改变比例</p></td>
</tr>
<tr class="row-even"><td><p>num_steps</p></td>
<td><p>迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="rfgsm">
<h2><span class="section-number">1.15. </span>RFGSM算法<a class="headerlink" href="#rfgsm" title="永久链接至标题">¶</a></h2>
<div class="section" id="id56">
<span id="id57"></span><h3>算法介绍<a class="headerlink" href="#id56" title="永久链接至标题">¶</a></h3>
<p>RFGSM算法全称是RAND-FGSM (R-FGSM)</p>
<p>使用FGSM方法进行对抗训练后的神经网络模型，在面对白盒攻击时比黑盒攻击更为鲁棒，所以提出了R-FGSM
增加随机梯度训练，用于防御对抗训练。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ x_{tmp} = x+\alpha \cdot sign(N(0^d, I^d))
\\ x^{'}=x_{tmp}+(\epsilon - \alpha)\cdot sign(\triangledown _ {x_{tmp}} J(x_{tmp}, l))\end{split}\]</div>
<p>其中α 和 ϵ 是参数，且α&lt;ϵ。</p>
</div>
<div class="section" id="id58">
<span id="id59"></span><h3>参数说明<a class="headerlink" href="#id58" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>沿着梯度方向步长的参数，当
该值越大时，每次为样本添加的扰动更大，对抗攻击强度越高。</p></td>
</tr>
<tr class="row-odd"><td><p>alpha</p></td>
<td><p>梯度步长的改变比例。</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="rllc">
<h2><span class="section-number">1.16. </span>RLLC算法<a class="headerlink" href="#rllc" title="永久链接至标题">¶</a></h2>
<div class="section" id="id60">
<span id="id61"></span><h3>算法介绍<a class="headerlink" href="#id60" title="永久链接至标题">¶</a></h3>
<p>Random Least Likely Class Attack</p>
</div>
<div class="section" id="id62">
<span id="id63"></span><h3>参数说明<a class="headerlink" href="#id62" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 15%" />
<col style="width: 85%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>沿着梯度方向步长的参数，当
该值越大时，每次为样本添加的扰动更大，对抗攻击强度越高。</p></td>
</tr>
<tr class="row-odd"><td><p>alpha</p></td>
<td><p>调节梯度步长系数的比例系数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="spsa">
<h2><span class="section-number">1.17. </span>SPSA算法<a class="headerlink" href="#spsa" title="永久链接至标题">¶</a></h2>
<div class="section" id="id64">
<span id="id65"></span><h3>算法介绍<a class="headerlink" href="#id64" title="永久链接至标题">¶</a></h3>
<p>SPSA算法全称是Multivariate stochastic approximation using a simultaneous
perturbation gradient approximation</p>
<p>SPSA算法非常适合于高维优化问题，即使在不确定目标的情况下，我们也可使用SPSA公式来产生对抗性攻击。在SPSA算法中，首先从Rademacher分布（即Bernoulli±1）中抽取一批n个样本，即</p>
<div class="math notranslate nohighlight">
\[v1,...,vn ∈\{1, -1\}^D\]</div>
<p>然后用随机方向上的有限差分估计逼近梯度。具体来说，对于第i个样本，估计的梯度gi计算如下：</p>
<div class="math notranslate nohighlight">
\[g_i=\frac{f(x_t+\delta v_i) - f(x - \delta v_i)}{2\delta v_i}\]</div>
<p>式中，δ是扰动大小，xt是第t次迭代时的扰动图像，f是要评估的模型。最后，SPSA对估计的梯度进行聚合，并在输入文本上执行投影梯度下降。整个过程按预先确定的迭代次数进行迭代。</p>
<p>完整的伪代码如下：</p>
<p><img alt="image7" src="../_images/图片23.png" /></p>
</div>
<div class="section" id="id66">
<span id="id67"></span><h3>参数说明<a class="headerlink" href="#id66" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 30%" />
<col style="width: 70%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>alpha</p></td>
<td><p>沿着梯度扰动的步长系数</p></td>
</tr>
<tr class="row-odd"><td><p>gamma</p></td>
<td><p>扰动的系数</p></td>
</tr>
<tr class="row-even"><td><p>c_par</p></td>
<td><p>迭代的基准噪声系数</p></td>
</tr>
<tr class="row-odd"><td><p>a_par</p></td>
<td><p>用来调整alpha系数的更新系数</p></td>
</tr>
<tr class="row-even"><td><p>sizeN</p></td>
<td><p>扰动样本更新的最大内层迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>min_vals_iter</p></td>
<td><p>最小的loss值下界</p></td>
</tr>
<tr class="row-even"><td><p>print_every</p></td>
<td><p>迭代过程中多少次迭代后打印一次</p></td>
</tr>
<tr class="row-odd"><td><p>max_iter</p></td>
<td><p>扰动样本更新的最大外层迭代次数</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="uap">
<h2><span class="section-number">1.18. </span>UAP算法<a class="headerlink" href="#uap" title="永久链接至标题">¶</a></h2>
<div class="section" id="id68">
<span id="id69"></span><h3>算法介绍<a class="headerlink" href="#id68" title="永久链接至标题">¶</a></h3>
<p>UAP算法的全称是Universal Adversarial Perturbation attack。</p>
<p>UAP算法提出了一种不易察觉的万能perturbation，它能使目前最好的分类器，在完成图片分类任务时出错。通过这个算法得到的perturbation，在各种神经网络情况下都能取得很好的效果。这揭示了目前分类器分类“判定边界”在高维度上的几何关系。</p>
<p>万能perturbation的构造算法：</p>
<p>算法得到的perturbation需要满足两个条件：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ ||v||_p \leq \xi
\\ \underset{x \sim u}{\mathbb{P}}(\hat{k}(x+v) \neq \hat{k}(x)) \geq 1 - \delta\end{split}\]</div>
<p>即第一是扰动的规模要比较小，第二是原来的数据叠加了扰动之后，分类器的输出错误率要大于一个阈值。整体的算法如下：</p>
<p><img alt="image8" src="../_images/图片24.png" /></p>
<p>其算法思想是对于图片数据中的每一个点，依次计算能使得最终分类器的输出错误的最小扰动，一直循环知道将整体分类错误的概率大于
1 − δ，其中 δ
为人为定义的分类器准确度。而算法的关键不是为了找到一个能使大多数样本分类错误的最小perturbation，而是用足够小的范数找到这样的一个扰动。</p>
</div>
<div class="section" id="id70">
<span id="id71"></span><h3>参数说明<a class="headerlink" href="#id70" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>dataset</p></td>
<td><p>使用的数据集类别</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="umifgsm">
<h2><span class="section-number">1.19. </span>UMIFGSM算法<a class="headerlink" href="#umifgsm" title="永久链接至标题">¶</a></h2>
<div class="section" id="id72">
<span id="id73"></span><h3>算法介绍<a class="headerlink" href="#id72" title="永久链接至标题">¶</a></h3>
<p>UMIFGSM算法全称是Utargeted Momentum Iterative Fast Gradient Sign
Method(UMI-FGSM)。</p>
<p>在迭代攻击方法中加入动量项（momentum term），提高对抗样本的转移性：</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ g_{t+1}=\mu \cdot g_t + \frac{\triangledown_x J(x_t^{adv}, y)}{|| \triangledown_x J(x_t^{adv}, y) ||_1}
\\ x_{t+1}^{adv}=x_{t}^{adv}+\alpha \cdot sign(g_{t+1})\end{split}\]</div>
<p>其中gt包含了直到t次迭代的梯度信息。</p>
</div>
<div class="section" id="id74">
<span id="id75"></span><h3>参数说明<a class="headerlink" href="#id74" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>epsilon</p></td>
<td><p>扰动的步长系数</p></td>
</tr>
<tr class="row-odd"><td><p>eps_iter</p></td>
<td><p>调节扰动的步长的比例系数</p></td>
</tr>
<tr class="row-even"><td><p>num_step</p></td>
<td><p>扰动样本更新的迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>decay_factor</p></td>
<td><p>调节动量项的步长</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="zoo">
<h2><span class="section-number">1.20. </span>ZOO算法<a class="headerlink" href="#zoo" title="永久链接至标题">¶</a></h2>
<div class="section" id="id76">
<span id="id77"></span><h3>算法介绍<a class="headerlink" href="#id76" title="永久链接至标题">¶</a></h3>
<p>ZOO算法全称为Zeroth Order Optimization Based Black-box。</p>
<p>ZOO攻击不可知，仅依赖于预测分数（例如类别机率或对数），使用数值估算梯度的预测。ZOO算法利用正负扰动带来的概率差估算一阶导（梯度）和二阶导，再利用ADAM或者牛顿法等方法更新x。本质为通过估算梯度将黑盒转换为白盒过程。</p>
<p>ZOO算法的损失函数和CW相似：</p>
<div class="math notranslate nohighlight">
\[minimize_x ||x-x_0||_2^2+c\cdot f(x,t) \; \; subject \; to \; x \in [0,1]^p\]</div>
<p>损失函数如上，左边保证对抗样本与真实input的相似，右边保证对抗样本能导致目标模型出错，具体如下：</p>
<p>目标攻击下：</p>
<div class="math notranslate nohighlight">
\[f(x,t)=max\{ \underset{i \neq t}{max} log[F(x)]_i - log[F(x)]_t, -K \}\]</div>
<p>非目标下</p>
<div class="math notranslate nohighlight">
\[f(x)=max\{log[F(x)]_{t_0} - \underset{i \neq t}{max} log[F(x)]_i , -K \}\]</div>
<p>随机选取一个坐标</p>
<p>估计梯度，h非常小，ei是一个只有i-th元素等于1的偏置向量。第二个只在牛顿法中才会使用。</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\ \hat{g}_i :=\frac{\partial f(x)}{\partial x_i} \approx \frac{f(x+he_i) - f(x - he_i)}{2h}
\\ \hat{h}_i := \frac{\partial ^2 f(x)}{\partial x_{ii}^2} \approx \frac{f(x+he_i) - 2f(x) + f(x - he_i)}{h^2}\end{split}\]</div>
<p><img alt="image9" src="../_images/图片25.png" /></p>
<p><img alt="image10" src="../_images/图片26.png" /></p>
</div>
<div class="section" id="id78">
<span id="id79"></span><h3>参数说明<a class="headerlink" href="#id78" title="永久链接至标题">¶</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 32%" />
<col style="width: 68%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>参数名称</p></th>
<th class="head"><p>参数说明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>solver</p></td>
<td><p>解算方法，Adam/Newton/Newton Adam</p></td>
</tr>
<tr class="row-odd"><td><p>resize_init_size</p></td>
<td><p>输入图像调整后尺寸</p></td>
</tr>
<tr class="row-even"><td><p>img_h</p></td>
<td><p>图像高度</p></td>
</tr>
<tr class="row-odd"><td><p>img_w</p></td>
<td><p>图像宽度</p></td>
</tr>
<tr class="row-even"><td><p>num_channels</p></td>
<td><p>图像通道数</p></td>
</tr>
<tr class="row-odd"><td><p>use_resize</p></td>
<td><p>是否需要调整图像尺寸</p></td>
</tr>
<tr class="row-even"><td><p>class_type_number</p></td>
<td><p>分类类别数目</p></td>
</tr>
<tr class="row-odd"><td><p>use_tanh</p></td>
<td><p>是否转化到tanh函数空间</p></td>
</tr>
<tr class="row-even"><td><p>confidence</p></td>
<td><p>班主判断攻击类别和预测类别是否相同或有固定偏差</p></td>
</tr>
<tr class="row-odd"><td><p>batch_size</p></td>
<td><p>批处理大小</p></td>
</tr>
<tr class="row-even"><td><p>init_const</p></td>
<td><p>Loss1初始化的调节系数（放大率）</p></td>
</tr>
<tr class="row-odd"><td><p>max_iter</p></td>
<td><p>最大迭代次数</p></td>
</tr>
<tr class="row-even"><td><p>binary_search_steps</p></td>
<td><p>用于搜索初始CONST的迭代次数</p></td>
</tr>
<tr class="row-odd"><td><p>beta1</p></td>
<td><p>用于产生中间图像数据的调节系数1</p></td>
</tr>
<tr class="row-even"><td><p>beta2</p></td>
<td><p>用于产生中间图像数据的调节系数2</p></td>
</tr>
<tr class="row-odd"><td><p>lr</p></td>
<td><p>用于更新原有数据和梯度，以及二阶导数关系的调节系数</p></td>
</tr>
<tr class="row-even"><td><p>reset_adam_after_found</p></td>
<td><p>是否在找到参数后重置adam</p></td>
</tr>
<tr class="row-odd"><td><p>early_stop_iters</p></td>
<td><p>提早结束的迭代次数</p></td>
</tr>
<tr class="row-even"><td><p>ABORT_EARLY</p></td>
<td><p>没有提升是否提前中断</p></td>
</tr>
<tr class="row-odd"><td><p>lower_bound</p></td>
<td><p>转化到tan函数空间的数据归一化下边界</p></td>
</tr>
<tr class="row-even"><td><p>upper_bound</p></td>
<td><p>转化到tan函数空间的数据归一化上边界</p></td>
</tr>
<tr class="row-odd"><td><p>print_every</p></td>
<td><p>迭代过程的打印间隔</p></td>
</tr>
<tr class="row-even"><td><p>use_log</p></td>
<td><p>是否保存过程中的Loss值</p></td>
</tr>
<tr class="row-odd"><td><p>save_modifier</p></td>
<td><p>是否保存过程中的攻击样本和原样本差值（修改值）</p></td>
</tr>
<tr class="row-even"><td><p>load_modifier</p></td>
<td><p>是否载入过程中的攻击样本和原样本差值（修改值）</p></td>
</tr>
<tr class="row-odd"><td><p>use_importance</p></td>
<td><p>是否使用概率方法选择生成数据挑选次序</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="02_extend.html" class="btn btn-neutral float-right" title="2. 扩展攻击算法" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="攻击算法介绍" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; 版权所有 2020, DIG

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>